{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sRT1pXllu9O",
        "outputId": "6b18d0bb-25f1-4c2f-c266-a1ae18cf8194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.13.tar.gz (63 kB)\n",
            "     ---------------------------------------- 0.0/63.3 kB ? eta -:--:--\n",
            "     ------------------------- -------------- 41.0/63.3 kB 1.9 MB/s eta 0:00:01\n",
            "     -------------------------------------- 63.3/63.3 kB 856.4 kB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\eshan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from kaggle) (1.16.0)\n",
            "Collecting certifi\n",
            "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\eshan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from kaggle) (2.8.2)\n",
            "Collecting requests\n",
            "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "     ---------------------------------------- 0.0/62.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 62.5/62.5 kB 3.5 MB/s eta 0:00:00\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "     ---------------------------------------- 0.0/77.1 kB ? eta -:--:--\n",
            "     ---------------------------------------- 77.1/77.1 kB 4.2 MB/s eta 0:00:00\n",
            "Collecting python-slugify\n",
            "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting urllib3\n",
            "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 0.0/78.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 78.2/78.2 kB ? eta 0:00:00\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\eshan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->kaggle) (0.4.6)\n",
            "Installing collected packages: text-unidecode, urllib3, tqdm, python-slugify, idna, charset-normalizer, certifi, requests, kaggle\n",
            "  Running setup.py install for kaggle: started\n",
            "  Running setup.py install for kaggle: finished with status 'done'\n",
            "Successfully installed certifi-2022.12.7 charset-normalizer-3.1.0 idna-3.4 kaggle-1.5.13 python-slugify-8.0.1 requests-2.29.0 text-unidecode-1.3 tqdm-4.65.0 urllib3-1.26.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: kaggle is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
            "[notice] To update, run: C:\\Users\\eshan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_jB4lLhUmLEM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "import json\n",
        "kaggle_token = {\"username\":\"datastorm087\",\"key\":\"f96ada8acdc2ce1a66d19c772cb2e9fc\"}\n",
        "with open(\"kaggle.json\", \"w\") as f:\n",
        "  token_json = json.dumps(kaggle_token)\n",
        "  f.write(token_json)\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2ZNDjX-nGGZ",
        "outputId": "5765bac5-5eb4-4f0a-c840-90389fe5bef2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\eshan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts\\kaggle-script.py\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('kaggle==1.5.13', 'console_scripts', 'kaggle')())\n",
            "  File \"c:\\Users\\eshan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts\\kaggle-script.py\", line 25, in importlib_load_entry_point\n",
            "    return next(matches).load()\n",
            "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\metadata\\__init__.py\", line 171, in load\n",
            "    module = import_module(match.group('module'))\n",
            "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"C:\\Users\\eshan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\kaggle\\__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"C:\\Users\\eshan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\eshan\\.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download -c data-storm-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfE5kd0BnLz0",
        "outputId": "992ae763-f7c5-4164-cc5a-91bd946e57dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "! unzip data-storm-4.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqFHxPxMp2tC",
        "outputId": "3e2b61f4-375c-4c5e-fbbb-57daa962bbf5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Store-info.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m store_info_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mStore-info.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m historical_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mHistorical-transaction-data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m testing_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mTesting-data.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Store-info.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "store_info_data = pd.read_csv('Store-info.csv')\n",
        "historical_data = pd.read_csv('Historical-transaction-data.csv')\n",
        "testing_data = pd.read_csv('Testing-data.csv')\n",
        "\n",
        "print(store_info_data.head())\n",
        "print(historical_data.head())\n",
        "print(testing_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAPgSFW34By3"
      },
      "outputs": [],
      "source": [
        "historical_data['transaction_date'] = pd.to_datetime(historical_data['transaction_date']).dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6f0IToR1Ydd",
        "outputId": "bc7b3d3a-7d6f-4b16-c519-2d52777c0883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               min        max\n",
            "shop_id                      \n",
            "SHOP001 2021-10-15 2021-12-15\n",
            "SHOP002 2021-10-15 2021-12-15\n",
            "SHOP003 2021-10-15 2021-12-15\n",
            "SHOP004 2021-10-15 2021-12-15\n",
            "SHOP005 2021-10-15 2021-12-15\n",
            "...            ...        ...\n",
            "SHOP123 2021-10-15 2021-12-15\n",
            "SHOP124 2021-10-15 2021-12-15\n",
            "SHOP125 2021-10-15 2021-12-15\n",
            "SHOP126 2021-10-15 2021-12-15\n",
            "SHOP127 2021-10-15 2021-12-15\n",
            "\n",
            "[124 rows x 2 columns]\n",
            "\n",
            "         min        max  count\n",
            "0 2021-10-15 2021-12-15    121\n",
            "1 2021-10-16 2021-12-15      1\n",
            "2 2021-10-22 2021-12-15      1\n",
            "3 2021-12-10 2021-12-15      1\n"
          ]
        }
      ],
      "source": [
        "# Convert transaction_date column to datetime format\n",
        "historical_data['transaction_date'] = pd.to_datetime(historical_data['transaction_date'])\n",
        "\n",
        "# Group the data by shop_id and get the date range for each group\n",
        "date_range = historical_data.groupby('shop_id')['transaction_date'].agg(['min', 'max'])\n",
        "\n",
        "# Print the date range for each shop\n",
        "print(date_range)\n",
        "\n",
        "print()\n",
        "\n",
        "# Group the data by date range for each shop and get the count of transactions\n",
        "grouped_data = date_range.groupby(['min', 'max']).size().reset_index(name='count')\n",
        "\n",
        "# Print the grouped data\n",
        "print(grouped_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3LuL_oG3q9vx",
        "outputId": "0e21f099-06b3-41eb-ff56-8d4047efb061"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'historical_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m items \u001b[39m=\u001b[39m historical_data\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mitem_description\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg(mode\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mitem_price\u001b[39m\u001b[39m'\u001b[39m, pd\u001b[39m.\u001b[39mSeries\u001b[39m.\u001b[39mmode))\n\u001b[0;32m      2\u001b[0m items\n",
            "\u001b[1;31mNameError\u001b[0m: name 'historical_data' is not defined"
          ]
        }
      ],
      "source": [
        "items = historical_data.groupby('item_description').agg(mode=('item_price', pd.Series.mode))\n",
        "items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "IQM4ht0NLARU",
        "outputId": "d5ad57c6-e015-4b60-853e-984bf433261a"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-adf3dfaeccc7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmode_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhistorical_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'mode'"
          ]
        }
      ],
      "source": [
        "mode_prices = items.to_dict()\n",
        "modes = mode_prices['mode']\n",
        "historical_data.dropna(subset=['item_description'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdBjl2DVLG97"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def replace_quantity(x):\n",
        "    #print(x)\n",
        "    if modes[x['item_description']]< x['item_price']:\n",
        "        #print(x)\n",
        "        x.quantity_sold = math.ceil(x.item_price/modes[x.item_description])\n",
        "    x.item_price = modes[x.item_description]\n",
        "    #x.revenue = modes[x.item_description]\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC03UxSxLNrT"
      },
      "outputs": [],
      "source": [
        "historical_data=historical_data.apply(replace_quantity,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA0U3VKKc_YG"
      },
      "outputs": [],
      "source": [
        "unique_items = historical_data['item_description'].unique()\n",
        "for item in unique_items:\n",
        "    print(item)\n",
        "\n",
        "\n",
        "def remove_last_word(x):\n",
        "    if isinstance(x, str):  # check if x is a string\n",
        "        return ' '.join(x.split(' ')[:-1])\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "historical_data['item_description'] = historical_data['item_description'].apply(remove_last_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t20BfBVTlPNl"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxaptxaQ7oMB"
      },
      "source": [
        "**Create New Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iOZCrZ6rPw3"
      },
      "source": [
        "*   Unique Customers per Store\n",
        "*   Transactions per Store i.e. Unique Invoice Numbers per Store\n",
        "*   Unique Items per Store\n",
        "*   Items per Store\n",
        "*   Revenue per Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJKr6bEY7s6p"
      },
      "outputs": [],
      "source": [
        "# Compute total number of unique customers\n",
        "unique_customers = historical_data.groupby(['shop_id'])['customer_id'].nunique()\n",
        "\n",
        "unique_customers = unique_customers.rename('unique_customers')\n",
        "\n",
        "store_info_data = store_info_data.merge(unique_customers, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUABLOfh-to3"
      },
      "outputs": [],
      "source": [
        "# Compute total number of unique transactions\n",
        "transactions = historical_data.groupby(['shop_id'])['invoice_id'].nunique()\n",
        "\n",
        "transactions = transactions.rename('transactions')\n",
        "\n",
        "store_info_data = store_info_data.merge(transactions, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTdAoBfu_q8w"
      },
      "outputs": [],
      "source": [
        "# Compute total number of unique items\n",
        "unique_items = historical_data.groupby('shop_id')['item_description'].nunique()\n",
        "\n",
        "unique_items = unique_items.rename('unique_items')\n",
        "\n",
        "store_info_data = store_info_data.merge(unique_items, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD4PpX_QfZ2a"
      },
      "outputs": [],
      "source": [
        "# Compute total number of items\n",
        "items = historical_data.groupby(['shop_id'])['quantity_sold'].sum()\n",
        "\n",
        "items = items.rename('items')\n",
        "\n",
        "store_info_data = store_info_data.merge(items, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQymmBxSAQWS"
      },
      "outputs": [],
      "source": [
        "# Compute total revenue\n",
        "historical_data['revenue'] = historical_data['item_price'] * historical_data['quantity_sold']\n",
        "\n",
        "revenue = historical_data.groupby('shop_id')['revenue'].sum()\n",
        "\n",
        "revenue = revenue.rename('revenue')\n",
        "\n",
        "store_info_data = store_info_data.merge(revenue, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkBoMmOeuX4L"
      },
      "outputs": [],
      "source": [
        "# Compute max item_price\n",
        "max_item_price = historical_data.groupby('shop_id')['item_price'].max()\n",
        "\n",
        "max_item_price = max_item_price.rename('max_item_price')\n",
        "\n",
        "store_info_data = store_info_data.merge(max_item_price, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_selRo7u2WB"
      },
      "outputs": [],
      "source": [
        "# Compute min item_price\n",
        "min_item_price = historical_data.groupby('shop_id')['item_price'].max()\n",
        "\n",
        "min_item_price = min_item_price.rename('min_item_price')\n",
        "\n",
        "store_info_data = store_info_data.merge(min_item_price, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcKD8A_Iu_lK"
      },
      "outputs": [],
      "source": [
        "# Compute max quantity_sold\n",
        "max_quantity_sold = historical_data.groupby('shop_id')['quantity_sold'].max()\n",
        "\n",
        "max_quantity_sold = max_quantity_sold.rename('max_quantity_sold')\n",
        "\n",
        "store_info_data = store_info_data.merge(max_quantity_sold, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV5TOT1yvCEH"
      },
      "outputs": [],
      "source": [
        "# Compute min quantity_sold\n",
        "min_quantity_sold = historical_data.groupby('shop_id')['quantity_sold'].max()\n",
        "\n",
        "min_quantity_sold = min_quantity_sold.rename('min_quantity_sold')\n",
        "\n",
        "store_info_data = store_info_data.merge(min_quantity_sold, on='shop_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sYNFP8vFLo3"
      },
      "outputs": [],
      "source": [
        "store_info_data[\"shop_profile\"] = store_info_data[\"shop_profile\"].replace({\"High\": 2, \"Moderate\": 1, \"Low\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX5Ji0LPiGVZ"
      },
      "outputs": [],
      "source": [
        "print(store_info_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uVeF-GaCSsc"
      },
      "outputs": [],
      "source": [
        "non_empty_profiles = store_info_data[~store_info_data['shop_profile'].isna()]\n",
        "empty_profiles = store_info_data[store_info_data['shop_profile'].isna()]\n",
        "\n",
        "# print(non_empty_profiles)\n",
        "# print(empty_profiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syyMimXPE8EV"
      },
      "outputs": [],
      "source": [
        "X = non_empty_profiles.drop(columns=[\"shop_id\", \"shop_profile\"])\n",
        "y = non_empty_profiles[\"shop_profile\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kV0mBXuB-1Gd"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import f1_score\n",
        "# Get the scores from various models\n",
        "def get_score (model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    return  f1_score(y_test,y_pred_test, average = 'micro')\n",
        "\n",
        "def get_score_train (model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    return  f1_score(y_train,y_pred_train, average = 'micro'), f1_score(y_test,y_pred_test, average = 'micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gRkbWS5DygU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "scores_l = [0]\n",
        "scores_knn = [0]\n",
        "scores_svc = [0]\n",
        "scores_rfc = [0]\n",
        "scores_gnb = [0]\n",
        "\n",
        "splits=10\n",
        "\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
        "\n",
        "def sub_lists (l):\n",
        "    lists = [[]]\n",
        "    for i in range(len(l) + 1):\n",
        "        for j in range(i):\n",
        "            lists.append(l[j: i])\n",
        "    return lists\n",
        " \n",
        "l1 = X.columns.to_list()\n",
        "combinations = sub_lists(l1)\n",
        "scores = []\n",
        "\n",
        "for combination in combinations:\n",
        "  if(len(combination)>0):\n",
        "      s1=0\n",
        "      s2=0\n",
        "      s3=0\n",
        "      for train_idx, test_idx in kf.split(X,y):\n",
        "          X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "          s1 += get_score(LogisticRegression(max_iter = 1000), X_train, X_test, y_train, y_test)\n",
        "          \n",
        "          s2 += get_score(SVC(), X_train, X_test, y_train, y_test)\n",
        "          \n",
        "          s3 += get_score(GaussianNB(), X_train, X_test, y_train, y_test)\n",
        "          \n",
        "      scores_l.append(s1/splits)\n",
        "      scores_svc.append(s2/splits)\n",
        "      scores_gnb.append(s3/splits)\n",
        "      if(s1/splits > 0.66):\n",
        "        print(\"s1\", combination, s1/splits)\n",
        "      if(s2/splits > 0.66):\n",
        "        print(\"s2\", combination, s2/splits)\n",
        "      if(s3/splits > 0.66):\n",
        "        print(\"s3\", combination, s3/splits)\n",
        "      # for n in range(27,29):\n",
        "      \n",
        "      #   scores = 0\n",
        "      #   for train_idx, test_idx in kf.split(X,y):\n",
        "          \n",
        "      #     X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "      #     scores += (get_score(RandomForestClassifier(n), X_train, X_test, y_train, y_test))\n",
        "\n",
        "      #     # scores += get_score(KNeighborsClassifier(n_neighbors=n), X_train, X_test, y_train, y_test)\n",
        "      #     # if(get_score(KNeighborsClassifier(n_neighbors=n), X_train, X_test, y_train, y_test) == 0.76):\n",
        "      #     #     print(combination, n)\n",
        "      #   scores_knn.append(scores/10)\n",
        "      #   if(round(scores*100) >= 66*10):\n",
        "      #     print(n, combination)\n",
        "      \n",
        "      \n",
        "\n",
        "print(\"Logistic Regression scores are: \", max(scores_l), \"\\n\")\n",
        "print(\"K Nearest Neighbours scores are: \", max(scores_knn), \"\\n\")\n",
        "print(\"Support Vector Machines scores are: \",max(scores_svc), \"\\n\")\n",
        "print(\"Random Forest Classifier scores are: \",max(scores_rfc), \"\\n\")\n",
        "print(\"Gaussian N B scores are: \",max(scores_gnb), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W061xu-E_qCo"
      },
      "outputs": [],
      "source": [
        "final_scores = []\n",
        "splits = 5\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for combination in combinations:\n",
        "  \n",
        "  if(len(combination)>3):\n",
        "    for n in [28]:\n",
        "      scores = 0\n",
        "      for train_idx, test_idx in kf.split(X,y):\n",
        "     \n",
        "      \n",
        "        X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "        scores += (get_score(RandomForestClassifier(n), X_train, X_test, y_train, y_test))\n",
        "\n",
        "        final_scores.append(scores/splits)\n",
        "        if(round(scores*100) >= 63*splits):\n",
        "          print(n, combination)\n",
        "print(max(final_scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aTvtf3qBvEm"
      },
      "outputs": [],
      "source": [
        "final_scores = []\n",
        "splits = 5\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for combination in combinations:\n",
        "  \n",
        "  if(len(combination)>3): \n",
        "    for n in range(2,50):\n",
        "      scores = 0\n",
        "      for train_idx, test_idx in kf.split(X,y):\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "        scores += (get_score(KNeighborsClassifier(n_neighbors=n), X_train, X_test, y_train, y_test))\n",
        "\n",
        "        final_scores.append(scores/splits)\n",
        "        if(round(scores*100) >= 66*splits):\n",
        "          print(n, combination, scores/splits)\n",
        "print(max(final_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTxYbtJRDrRW"
      },
      "outputs": [],
      "source": [
        "final_scores = []\n",
        "splits = 5\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for combination in combinations:\n",
        "  if(len(combination)>3): \n",
        "    for n in range(1):\n",
        "      scores = 0\n",
        "      for train_idx, test_idx in kf.split(X,y):\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "        scores += (get_score(GaussianNB(), X_train, X_test, y_train, y_test))\n",
        "\n",
        "        final_scores.append(scores/splits)\n",
        "        if(round(scores*100) >= 61*splits):\n",
        "          print(n, combination, scores/splits)\n",
        "print(max(final_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znQTgx_GECqr"
      },
      "outputs": [],
      "source": [
        "final_scores = []\n",
        "splits = 5\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for combination in combinations:\n",
        "  \n",
        "  if(len(combination)>3): \n",
        "    for n in range(1):\n",
        "      scores = 0\n",
        "      for train_idx, test_idx in kf.split(X,y):\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "        scores += (get_score(SVC(), X_train, X_test, y_train, y_test))\n",
        "\n",
        "        final_scores.append(scores/splits)\n",
        "        if(round(scores*100) >= 61*splits):\n",
        "          print(n, combination, scores/splits)\n",
        "print(max(final_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlpiJie0Gn3C"
      },
      "outputs": [],
      "source": [
        "! pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1gE2lD6GrMd"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "final_scores = []\n",
        "splits = 5\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for combination in combinations:\n",
        "  \n",
        "  if(len(combination)>3): \n",
        "    for n in range(100, 300, 100):\n",
        "      scores = 0\n",
        "      for train_idx, test_idx in kf.split(X,y):\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = X[X.columns.intersection(combination)].iloc[train_idx], X[X.columns.intersection(combination)].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "        scores += (get_score(xgb.XGBClassifier(n_estimators=n, objective='multi:softprob', tree_method='hist', eta=0.1, max_depth=5), X_train, X_test, y_train, y_test))\n",
        "\n",
        "        final_scores.append(scores/splits)\n",
        "        if(round(scores*100) >= 61*splits):\n",
        "          print(n, combination, scores/splits)\n",
        "print(max(final_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8S3rWMuUQzD"
      },
      "outputs": [],
      "source": [
        "score_arr = []\n",
        "splits = 5\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for train_idx, test_idx in kf.split(X,y):\n",
        "  X_train, X_test, y_train, y_test = X[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']].iloc[train_idx], X[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "  score_arr.append(get_score(xgb.XGBClassifier(n_estimators=200, objective='multi:softprob', tree_method='hist', eta=0.1, max_depth=5), X_train, X_test, y_train, y_test))\n",
        "print(score_arr)\n",
        "print(sum(score_arr)/splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVB0nAcehoKz"
      },
      "outputs": [],
      "source": [
        "score_arr = []\n",
        "splits = 3\n",
        "kf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=10)\n",
        "for train_idx, test_idx in kf.split(X,y):\n",
        "  X_train, X_test, y_train, y_test = X[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']].iloc[train_idx], X[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']].iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
        "  score_arr.append(get_score_train(LogisticRegression(max_iter = 1000), X_train, X_test, y_train, y_test))\n",
        "print(score_arr)\n",
        "print(\"test score:\", sum([x[1] for x in score_arr])/splits)\n",
        "print(\"train_score:\", sum([x[0] for x in score_arr])/splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hds-GnIwnEnN"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression(max_iter = 1000)\n",
        "lr.fit(X[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']],y)\n",
        "\n",
        "X_test = empty_profiles.drop(columns=[\"shop_id\", \"shop_profile\"])\n",
        "\n",
        "y_test = lr.predict(X_test[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']])\n",
        "\n",
        "y_train_pred = lr.predict(X[['shop_area_sq_ft', 'unique_customers', 'transactions', 'unique_items', 'items']])\n",
        "\n",
        "print(f1_score(y,y_train_pred, average = 'macro'))\n",
        "\n",
        "test_preds = pd.DataFrame({'shop_id':empty_profiles['shop_id'],'shop_profile':y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKlRAN8in40p"
      },
      "outputs": [],
      "source": [
        "len(test_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXuQTh8xn861"
      },
      "outputs": [],
      "source": [
        "test_preds[\"shop_profile\"] = test_preds[\"shop_profile\"].replace({2: \"High\", 1:\"Moderate\", 0:\"Low\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4H819YhoAAN"
      },
      "outputs": [],
      "source": [
        "filename = 'DataStorm087_Day1_2.csv'\n",
        "test_preds.to_csv(filename,index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
